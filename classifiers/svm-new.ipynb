{
 "metadata": {
  "name": "svm-new"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# SVM classification of surface residues"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook documents my work on SVM classification of surface residues of receptors in peptide-protein interactions.\n",
      "The data is read directly from Dana's early work on PeptiDB, analyzing surface residues in that data set using various tools.\n",
      "\n",
      "First, import the necessary Python modules for analysis, primarily SciKit-Learn (sklearn) used for machine learning and statistical analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import os\n",
      "import numpy as np\n",
      "from scipy import interp\n",
      "import pylab as pl\n",
      "import hashlib\n",
      "\n",
      "# caching/serialization libraries\n",
      "import pickle\n",
      "import joblib\n",
      "\n",
      "from datetime import datetime\n",
      "from texttable import Texttable\n",
      "from IPython.core.display import Latex, HTML\n",
      "\n",
      "from itertools import combinations, chain\n",
      "from treedict import TreeDict\n",
      "\n",
      "from sklearn import svm, datasets, metrics, cross_validation, preprocessing\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "from sklearn.cross_validation import StratifiedKFold, KFold, LeaveOneLabelOut\n",
      "\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Debug settings:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "debug = False\n",
      "\n",
      "DEBUG_DATASET_SIZE = 1000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "THESIS_SRC = '/home/assaff/projects/msc-thesis/source'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define a caching directory, so we don't need to repeat computational work:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cache_verbosity = 1 if debug else 0\n",
      "memory = joblib.Memory(cachedir='/home/assaff/projects/peptalk/classifiers/cache', verbose=cache_verbosity,)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "memory.clear()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#memory.cache(func=svm.SVC)\n",
      "memory.cache(func=pd.read_csv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading data from CSV files:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load precomputed data about the samples encoded as tables in CSV format, and scale the data such that each feature has $\\mu = 0$ and $\\sigma^2 = 1$.\n",
      "\n",
      "These data include PDB identifiers, residue numbers, feature values for each of our six features, and lastly $\\Delta\\Delta G$ values for each residue.\n",
      "\n",
      "Note: $\\Delta\\Delta G$ values for residues in the unbound sets are actually calculated for their *bound* counterparts. \n",
      "The correspondence was inferred using a local sequence alignment between bound and unbound receptors, as detailed in the `match-bound-unbound` notebook."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Setup learning:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Training on *bound* data set:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use the bound feature array as $X$, our feature data, and scale it such that each feature has $\\mu = 0$ and $\\sigma^2 = 1$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load $\\Delta\\Delta G$ values for all residues in the bound set, and define binary classification (`y`) as \"binder\" when a residue has $\\Delta\\Delta G > 0$:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load a list of PDB IDs for each of the samples in the data set, i.e. with length the same as `y`. This is used later in `LeaveOneLabelOut` cross-validation, to make sure that all the residues from any one protein are in the same subset of the samples (i.e. fold)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## ROC curves of different classification configs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### AUC and feature weight over all features, using cross-validation data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start by defining a K-fold partition of the data, plus a SV classifier. \n",
      "The partition can be either a random partition, a random stratified partition, or by label.\n",
      "\n",
      "In our case, we use 4-fold leave-one-label-out cross-validation. \n",
      "This means we divide the data set of residues into 4 disjoint subsets, such that all the residues of any one receptor are in the same subset. \n",
      "The subsets are roughly similar in size, but cannot be guaranteed to be an equal partition of the data.\n",
      "\n",
      "The partition is accomplished by assigning an integer label to each residue that is the ASCII value of that residue's PDB ID, modulo the number of subsets we want (in our case, 4). \n",
      "The ASCII value of a string is the sum of ASCII numbers of each of its characters. \n",
      "Therefore, all residues of the same receptor will have the same PDB ID, hence the same ASCII value, hence the same label."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import data\n",
      "bound_set = data.prepDataSet('bound.data.csv', truncate=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples, n_features = bound_set.X.shape\n",
      "\n",
      "# Initialize classifier with crossvalidation\n",
      "k_folds = 4\n",
      "\n",
      "#cv = KFold(len(y), k=k_folds)\n",
      "#cv = StratifiedKFold(y, k=k_folds)\n",
      "\n",
      "hash_to_k = lambda s: (sum(ord(c) for c in hashlib.sha1(s).hexdigest()) % k_folds)\n",
      "pdb_labels = np.array([hash_to_k(s) for s in bound_set.pdbs])\n",
      "cv = LeaveOneLabelOut(labels=pdb_labels)\n",
      "\n",
      "classifier = svm.SVC(kernel='linear', probability=True, class_weight='auto')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we calculate performance statistics of the classifier, such that for each of the labels we defined above, we:\n",
      "\n",
      "1. Train (or fit) the classifier on other labels, and record the feature weights for the trained model.\n",
      "2. Predict the likelihood of residues from the training set (i.e. other labels) to be binders, and from the test set (the current label).\n",
      "3. Using these predictions, calculate ROC curves for the training and test sets, and record the AUC for each of them.\n",
      "\n",
      "Finally, print all statistics detailed above in a table, where each row represents one label. \n",
      "Additionally, print mean values for all columns (feature weights, AUCs)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat_weights = np.zeros((len(cv), n_features))\n",
      "test_aucs = np.zeros(len(cv))\n",
      "train_aucs = np.zeros(len(cv))\n",
      "\n",
      "#clf_table = Texttable(max_width=160)\n",
      "#clf_table.set_deco(Texttable.HEADER | Texttable.VLINES)\n",
      "#clf_table.set_cols_dtype(list('t' + 'a'*n_features + 'cc'))\n",
      "#clf_table.set_cols_align(list('l' + 'c'*n_features + 'cc'))\n",
      "#clf_table.set_precision(4)\n",
      "#clf_table.header(['CV subset'] + feature_names + ['AUC (training)', 'AUC (testing)'])\n",
      "\n",
      "mean_tpr = 0.0\n",
      "mean_tpr_train = 0.0\n",
      "fpr_grid = np.linspace(0, 1, 100)\n",
      "all_tpr = []\n",
      "\n",
      "print \"Calculating CV: \",\n",
      "for i, (train, test) in enumerate(cv):\n",
      "    print i, #np.c_[y[train], X_c[train,:]]\n",
      "    classifier.fit(bound_set.X[train,:], bound_set.y[train])\n",
      "    feat_weights[i] = classifier.coef_\n",
      "    \n",
      "    # Test on the training set\n",
      "    tr_probas_ = classifier.predict_proba(bound_set.X[train,:])\n",
      "    tr_fpr, tr_tpr, tr_thresholds = roc_curve(bound_set.y[train], tr_probas_[:,1])\n",
      "    train_aucs[i] = auc(tr_fpr, tr_tpr)\n",
      "    mean_tpr_train += interp(fpr_grid, tr_fpr, tr_tpr, left=0, right=1)\n",
      "    \n",
      "    #Test on the test set\n",
      "    probas_ = classifier.predict_proba(bound_set.X[test,:])\n",
      "    # Compute ROC curve and area the curve\n",
      "    fpr, tpr, thresholds = roc_curve(bound_set.y[test], probas_[:, 1])\n",
      "    test_aucs[i] = auc(fpr, tpr)\n",
      "    mean_tpr += interp(fpr_grid, fpr, tpr, left=0, right=1)\n",
      "\n",
      "    #clf_table.add_row([\"CV %d\" % i] + feat_weights[i].tolist() + [train_aucs[i], test_aucs[i]])\n",
      "\n",
      "print 'Done.'\n",
      "stats = np.c_[feat_weights, train_aucs, test_aucs]\n",
      "cv_names = [['CV%d'%i] for i in range(len(cv))]\n",
      "#for i in range(len(cv)):\n",
      "#    clf_table.add_row(cv_names[i] + stats[i].tolist())\n",
      "#clf_table.add_row(['Mean'] + stats.mean(axis=0).tolist())\n",
      "\n",
      "mean_tpr /= len(cv)\n",
      "mean_tpr[-1] = 1.0\n",
      "mean_auc = auc(fpr_grid, mean_tpr)\n",
      "\n",
      "mean_tpr_train /= len(cv)\n",
      "mean_tpr_train[-1] = 1.0\n",
      "mean_auc_train = auc(fpr_grid, mean_tpr_train)\n",
      "#print \n",
      "#print clf_table.draw()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = pd.DataFrame(stats, columns=bound_set.feature_set.features + ['AUC (training)', 'AUC (testing)'], index=['CV%d' % i for i in range(k_folds)])\n",
      "#display(t.append(t.describe()))\n",
      "display(\n",
      "        Latex('Feature weights alone:'), \n",
      "        t.ix[:,:6].abs(),\n",
      "        )\n",
      "\n",
      "tbl_svm_coefs = t.append(t.describe().ix[1:3,:])\n",
      "\n",
      "display(\n",
      "        Latex('Entire stats table:'), \n",
      "        tbl_svm_coefs,\n",
      "        )\n",
      "\n",
      "tbl_svm_coefs.to_csv(os.path.join(THESIS_SRC, '_tables', 'table-svm-coefs.csv'), float_format='%4.2f')\n",
      "#display(t.describe())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Compare classifiers *trained* on different feature sets:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set up different configurations:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import config"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_features = bound_set.feature_set.all_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "delta_configs = [config.createConfig(all_features)]\n",
      "single_configs = [config.createConfig(all_features)]\n",
      "for feature_set in combinations(all_features, len(all_features)-1):\n",
      "    delta_configs.append(config.createConfig(feature_set))\n",
      "    single_configs.append(config.createConfig(list(set(all_features).difference(set(feature_set)))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "protocol_features = {\n",
      "                     'FTMap': ['Fragment normalized rank', 'Number of fragments'],\n",
      "                     'ConSurf': ['Conservation score'],\n",
      "                     'CASTp'  : ['Normalized pocket rank'],\n",
      "                     'Sequence' : ['AA hydrophobic', 'AA polar'],\n",
      "                     }\n",
      "print protocol_features\n",
      "\n",
      "delta_protocol_configs = [config.createConfig(all_features)]\n",
      "single_protocol_configs = [config.createConfig(all_features)]\n",
      "for protocol, prot_features in protocol_features.items():\n",
      "    delta_protocol_configs.append(config.createConfig(list(set(all_features).difference(set(prot_features))), title_meta=protocol+' features'))\n",
      "    single_protocol_configs.append(config.createConfig(prot_features, title_meta=protocol+' features'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Iterate configurations, and for each fold in the CV partifion, fit the model on the training set and test on both.\n",
      "2. Collect the data and present mean AUCs for each config in a table.\n",
      "3. Plot mean ROC curves of the different configs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def testConfigs(configs):\n",
      "    rcParams['figure.figsize'] = (12.0, 9.0)\n",
      "    n_configs = len(configs)\n",
      "    \n",
      "    for i, c in enumerate(configs):\n",
      "        probas_ = config.predictClassifier(c)#clfs[i]) #.predict_proba(c.test_set.X)\n",
      "    \n",
      "        display(Latex(\"Calculating predictions on feature set: %s\" % c.title))\n",
      "        fpr, tpr, thresholds = roc_curve(c.test_set.y, probas_[:, 1])\n",
      "        fpr_grid = np.linspace(0, 1, 100)\n",
      "        tpr_interp = interp(fpr_grid, fpr, tpr, left=0, right=1)\n",
      "        roc_auc = auc(fpr_grid, tpr_interp)\n",
      "        \n",
      "        pl.plot(fpr_grid, tpr_interp, label='%s (AUC = %0.2f)' % (c.title, roc_auc))\n",
      "        \n",
      "    pl.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random')\n",
      "    \n",
      "    pl.xlim([-0.05, 1.05])\n",
      "    pl.ylim([-0.05, 1.05])\n",
      "    pl.xlabel('False Positive Rate')\n",
      "    pl.ylabel('True Positive Rate')\n",
      "    pl.title('Comparison of classifier configurations' + '\\n'+\n",
      "            'Mean ROC curves, performance measured on test set')\n",
      "    pl.legend(loc=\"lower right\")\n",
      "    \n",
      "    pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "delta_clfs = config.trainConfigClassifiers(delta_configs)\n",
      "testConfigs(delta_configs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "single_clfs = config.trainConfigClassifiers(single_configs)\n",
      "testConfigs(single_configs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "delta_protocol_clfs = config.trainConfigClassifiers(delta_protocol_configs)\n",
      "testConfigs(delta_protocol_configs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "single_protocol_clfs = config.trainConfigClassifiers(single_protocol_configs)\n",
      "testConfigs(single_protocol_configs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Recursive feature elimination"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_selection import RFECV, RFE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -1 unboundMat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfe = RFE(estimator=classifier, n_features_to_select=3, step=1)\n",
      "rfe.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print rfe.support_\n",
      "print rfe.ranking_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfecv = RFECV(classifier, step=1, cv=StratifiedKFold(y_train, 3),\n",
      "                loss_func=metrics.zero_one)\n",
      "rfecv.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Optimal number of features : %d\" % rfecv.n_features_\n",
      "print \"Support:\", rfecv.support_\n",
      "print \"Feature ranking:\", rfecv.ranking_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl.figure()\n",
      "pl.xlabel(\"Number of features selected\")\n",
      "pl.ylabel(\"Cross validation score (nb of misclassifications)\")\n",
      "pl.plot(xrange(1, len(rfecv.cv_scores_) + 1), rfecv.cv_scores_)\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}