{
 "metadata": {
  "name": "svm-preprocessing"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "SVM features: preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section we calculate quantitative residue descriptors used later in \n",
      "the SVM classification flow.\n",
      "\n",
      "We start by defining parameters of one PeptiDB entry, for which we calculate \n",
      "all the descriptors. \n",
      "\n",
      "The goal of each section is a function that accepts an AtomGroup object of \n",
      "the receptor (single chain), and optionally other parameters, returning a \n",
      "data frame or series object, with length equal to the number of residues in \n",
      "the receptor, where columns are one or more features of the residues. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# flag to mark cells that should run only in interactive mode\n",
      "interactive_session = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import prody\n",
      "prody.confProDy(verbosity='error')\n",
      "from sklearn import preprocessing\n",
      "\n",
      "import subprocess\n",
      "import tempfile\n",
      "import os, sys, shutil\n",
      "import string, re\n",
      "\n",
      "from collections import OrderedDict\n",
      "import itertools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import joblib\n",
      "memory = joblib.Memory('cache')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j = os.path.join\n",
      "PROJECT_PATH = '/home/assaff/projects/peptalk'\n",
      "\n",
      "DATA_PATH = j(PROJECT_PATH, 'data')\n",
      "PEPTIDB_DATA_PATH = j(DATA_PATH, 'peptiDB')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file receptor_data.py\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import prody\n",
      "prody.confProDy(verbosity='error')\n",
      "from sklearn import preprocessing\n",
      "\n",
      "import subprocess\n",
      "import tempfile\n",
      "import os, sys, shutil\n",
      "import string, re\n",
      "\n",
      "from collections import OrderedDict\n",
      "import itertools\n",
      "\n",
      "import joblib\n",
      "memory = joblib.Memory('cache')\n",
      "\n",
      "import naccess\n",
      "import fpocket\n",
      "\n",
      "j = os.path.join\n",
      "PROJECT_PATH = '/home/assaff/projects/peptalk'\n",
      "\n",
      "DATA_PATH = j(PROJECT_PATH, 'data')\n",
      "PEPTIDB_DATA_PATH = j(DATA_PATH, 'peptiDB')\n",
      "\n",
      "class ReceptorData:\n",
      "    \n",
      "    def __init__(self, pdbid, context='bound'):\n",
      "        self.pdbid = pdbid.upper()\n",
      "        self.context = context\n",
      "        bound = True if context=='bound' else False\n",
      "        \n",
      "        self.DATA_PATH = j(PEPTIDB_DATA_PATH, self.context)\n",
      "        self.PDB_DATA_PATH = j(self.DATA_PATH, self.context+'Set', 'mainChain' if bound else '')\n",
      "        self.FTMAP_DATA_PATH = j(self.DATA_PATH, 'FTMapAnalysis', 'ftmapData')\n",
      "        self.CONSURF_DATA_PATH = j(self.DATA_PATH, 'ConSurfAnalysis', 'data')\n",
      "        \n",
      "        self.receptor_filename = j(self.PDB_DATA_PATH, '%s.pdb' % self.pdbid)\n",
      "        self.receptor_atoms = prody.parsePDB(self.receptor_filename).protein\n",
      "        \n",
      "        self.receptor_chain = self.receptor_atoms.getHierView().iterChains().next()\n",
      "        #print \"###%s###\" % self.receptor_filename\n",
      "        self.resnum_index = pd.MultiIndex.from_tuples(\n",
      "                            zip(\n",
      "                                [pdbid]*self.receptor_chain.numResidues(),\n",
      "                                self.receptor_chain.ca.getResnums()\n",
      "                            ), \n",
      "                                names = [\n",
      "                                    'PDB identifier', \n",
      "                                    'Residue number',\n",
      "                                        ]\n",
      "                                )\n",
      "        self.df = pd.DataFrame(index=self.resnum_index)\n",
      "        print self.pdbid\n",
      "        \n",
      "    def conservation(self,):\n",
      "        consurf_pdb_filename = os.path.join(self.CONSURF_DATA_PATH, self.pdbid, 'pdbFILE_view_ConSurf.pdb')\n",
      "        p = prody.parsePDB(consurf_pdb_filename)\n",
      "        consurf_chain = p.getHierView().iterChains().next()\n",
      "        return pd.DataFrame(\n",
      "                            columns=['Conservation-score'],\n",
      "                            index=self.resnum_index,\n",
      "                            data=consurf_chain.ca.getBetas(),\n",
      "                            )\n",
      "    \n",
      "    def sasa(self,):\n",
      "        rsa = naccess.getResidueSasa(self.receptor_atoms)\n",
      "        return pd.DataFrame(\n",
      "                            rsa.values, \n",
      "                            index=self.resnum_index,\n",
      "                            columns=rsa.columns, \n",
      "                            )\n",
      "    \n",
      "    def ftmap(self,):\n",
      "        ######\n",
      "        # calculate consensus clusters (ccls) statistics, independent of specific residues:\n",
      "        ftmap_atoms = prody.parsePDB(j(self.FTMAP_DATA_PATH, '{}.map.clean.pdb'.format(self.pdbid)))\n",
      "        \n",
      "        ccls = pd.DataFrame(\n",
      "                            list(ftmap_atoms.getHierView().iterChains()), \n",
      "                            #index=range(h.numChains()),\n",
      "                            columns=['chain'],\n",
      "                            )\n",
      "        \n",
      "        ccls['cs_size'] = ccls.chain.map(lambda chain: chain.numResidues())\n",
      "        \n",
      "        ccls['cs_rank'] = ccls.cs_size.rank(ascending=False, method='first')\n",
      "        DUMMY_CCL_RANK = 15 #ccls.cs_rank.max()+1\n",
      "        \n",
      "        ######\n",
      "        def nearby_ccls(resnum, cutoff=4.5):\n",
      "            res = self.receptor_chain.getResidue(resnum)\n",
      "            res_contacts = prody.Contacts(res.noh.getCoords())\n",
      "            is_near_res = lambda ccl: res_contacts.select(cutoff, ccl) is not None\n",
      "                            #ag.select('same chain as within {} of res'.format(float(cutoff)), \n",
      "                            #                res=res) is not None\n",
      "            \n",
      "            return ccls[ccls.chain.map(is_near_res)].cs_rank.tolist()\n",
      "        \n",
      "        def nearby_ccl(resnum, cutoff=4.5):\n",
      "            ccls_near_ranks = nearby_ccls(resnum, cutoff)\n",
      "            return ccls_near_ranks[0] if ccls_near_ranks else DUMMY_CCL_RANK#np.nan\n",
      "        \n",
      "        def num_nearby_ccls(resnum):\n",
      "            return len(nearby_ccls(resnum))\n",
      "        \n",
      "        ind = pd.Index(self.receptor_chain.ca.getResnums())\n",
      "        \n",
      "        res_ccl_map = pd.DataFrame(\n",
      "                    columns=['resnum','cs_rank', 'num_nearby_cs'], \n",
      "                    data=zip(\n",
      "                        ind.tolist(), \n",
      "                        map(nearby_ccl, ind),\n",
      "                        map(num_nearby_ccls, ind),\n",
      "                        ),\n",
      "                    )\n",
      "        \n",
      "        ccls = ccls.append({'chain': None, 'cs_size': 1, 'cs_rank': DUMMY_CCL_RANK}, ignore_index=True)\n",
      "        \n",
      "        ccls['cs_normalized_rank'] = ccls.cs_rank / ccls.cs_size\n",
      "        \n",
      "        ccls['cs_svm_size'] = np.minimum(\n",
      "                                    np.ceil(ccls.cs_size / float(5)),\n",
      "                                    4\n",
      "                                    )\n",
      "        ccls['cs_svm_rank'] = np.minimum(ccls.cs_rank, 5)\n",
      "        \n",
      "        ccls['cs_svm_norm_rank'] = ccls['cs_svm_rank'] / ccls['cs_svm_size'].astype(float)\n",
      "        \n",
      "        \n",
      "        res_ccl_stats = res_ccl_map.merge(\n",
      "                        ccls.drop(['chain'], axis=1), \n",
      "                        how='inner', \n",
      "                        on='cs_rank',\n",
      "                            ).set_index('resnum')\n",
      "        return res_ccl_stats.reindex(index=self.resnum_index, level=1)\n",
      "    \n",
      "    def pockets(self,):\n",
      "        pocket_data = fpocket.pocket_data(self.receptor_filename)\n",
      "        DUMMY_POCKET_RANK = 15#pocket_data['Pocket rank'].max()+1\n",
      "        \n",
      "        def nearby_pocket(resnum, cutoff=4.5):\n",
      "            \n",
      "            res = self.receptor_chain.getResidue(resnum)\n",
      "        \n",
      "            res_contacts = prody.Contacts(res.noh.getCoords())\n",
      "            is_near_res = lambda pocket_atoms: res_contacts.select(cutoff, pocket_atoms) is not None\n",
      "        \n",
      "            pockets_near_rank = pocket_data.ix[\n",
      "                            pocket_data['Pocket atoms'].map(is_near_res), \n",
      "                            'Pocket rank'\n",
      "                                ].tolist()\n",
      "            return pockets_near_rank[0] if pockets_near_rank else DUMMY_POCKET_RANK# np.nan\n",
      "            \n",
      "        res_pocket_map = pd.DataFrame(\n",
      "                              columns = ['resnum', 'Pocket rank'],\n",
      "                              index=self.resnum_index,\n",
      "                              data=[(resnum, nearby_pocket(resnum)) for resnum \n",
      "                                    in self.resnum_index.get_level_values(1)],\n",
      "                              )\n",
      "        pocket_data = pocket_data.append({colname: DUMMY_POCKET_RANK if colname=='Pocket rank' else 0 \n",
      "                            for colname in pocket_data.columns}, \n",
      "                                ignore_index=True,)\n",
      "        \n",
      "        res_pocket_stats = res_pocket_map.merge(\n",
      "                            pocket_data.drop(['Pocket atoms'], axis=1), \n",
      "                            how='inner', \n",
      "                            on='Pocket rank', \n",
      "                                ).set_index('resnum')\n",
      "        \n",
      "        return res_pocket_stats.reindex(res_pocket_map.index, level=1)\n",
      "    \n",
      "    def aa_props(self,):\n",
      "        aa_props = pd.read_csv('aa_props.csv', true_values='X', false_values='-',)\n",
      "        aa_props['resname'] = [s.upper() for s in aa_props['Abbrev.']]\n",
      "        \n",
      "        aa_props['pKa'] = [float(n) for n in aa_props['pKa'].replace('-', '0.0')]\n",
      "        aa_props = aa_props.replace('-', 'None')\n",
      "        aa_props = aa_props.ix[:, 'Hydrophobic':]\n",
      "        \n",
      "        res_aa_map = pd.DataFrame(\n",
      "                              columns=['resnum', 'resname'],\n",
      "                              index=self.resnum_index,\n",
      "                              data=[(resnum, self.receptor_chain.getResidue(resnum).getResname())\n",
      "                                    for resnum in self.resnum_index.get_level_values(1)],\n",
      "                            )\n",
      "        res_aa_stats = res_aa_map.merge(aa_props, how='inner', on='resname',).set_index('resnum')\n",
      "        return res_aa_stats.reindex(res_aa_map.index, level=1).drop(['resname'], axis=1)\n",
      "            \n",
      "    #@property\n",
      "    def data(self,):\n",
      "        if not hasattr(self, '_data'):\n",
      "            feature_generators = OrderedDict(\n",
      "                                         NAccess=self.sasa(),\n",
      "                                         ConSurf=self.conservation(),\n",
      "                                         FTMap=self.ftmap(),\n",
      "                                         FPocket=self.pockets(),\n",
      "                                         Physico=self.aa_props(),\n",
      "                                         )\n",
      "            \n",
      "            tuples = list(itertools.chain(*[\n",
      "                         [(prot_name, col_name) for col_name in prot_df.columns.tolist()]\n",
      "                         for prot_name, prot_df in feature_generators.items()\n",
      "                     ]))\n",
      "            idex = pd.MultiIndex.from_tuples(tuples)\n",
      "            \n",
      "            self._data = pd.concat(feature_generators.values(), axis=1, keys=feature_generators.keys())\n",
      "        return self._data\n",
      "        \n",
      "@memory.cache\n",
      "def recdata(pdbid, context='bound'):\n",
      "    return ReceptorData(pdbid, context).data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@memory.cache\n",
      "def recdata(pdbid, context='bound'):\n",
      "    return ReceptorData(pdbid, context).data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Aggregating over all entries in PeptiDB:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def header(val):\n",
      "    s = str(val).replace('.', '')\n",
      "    return '-'.join(s.split())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import receptor_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def data_set(context='bound'):\n",
      "    csv_filename = '%s.data.csv' % context\n",
      "    print \"Reading data from %s\" % csv_filename\n",
      "    old_df = pd.read_csv(csv_filename, index_col=[0,1])\n",
      "    \n",
      "    # read alascan data into a DF object\n",
      "    alascan_df = pd.DataFrame(\n",
      "                              data=old_df['ALASCAN_DDG'].values,\n",
      "                              index=old_df.index,\n",
      "                              columns=pd.MultiIndex.from_tuples([('Rosetta AlaScan', 'Residue ddG')],),\n",
      "                              )\n",
      "    \n",
      "    # iterate over all PDB ids, and concatenate the data tables.\n",
      "    pdbs_list = old_df.index.levels[0][:3]\n",
      "    features_df = pd.concat([receptor_data.recdata(pdbid, context) for pdbid in pdbs_list],)\n",
      "    \n",
      "    # merge (inner join) the two tables based on their residue number indices.\n",
      "    merged_table = pd.merge(features_df, alascan_df, how='inner', left_index=True, right_index=True, )\n",
      "    merged_table.index.names = features_df.index.names\n",
      "    return merged_table\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def encode_data(data):\n",
      "    '''\n",
      "    Prepares a PeptiDB data table for quantitative analysis (namely SVM).\n",
      "    Iterates over all columns in the table, each encoded according to:\n",
      "    - String-value columns are encoded to integer values, and \n",
      "        then binarized as separate binary variables. E.g. residue name column is initially\n",
      "        encoded 3-letter codes as string. The result is a DataFrame object with 20 columns,\n",
      "        each dedicated to one amino acid.\n",
      "    - Boolean values: left unchanged\n",
      "    - Float and integers: left unchanged\n",
      "\n",
      "    Also, column names are stripped of any spaces and periods.\n",
      "\n",
      "    Finally, all new columns are concatenated and returned as one DataFrame.\n",
      "    '''\n",
      "    \n",
      "    feature_data = OrderedDict()\n",
      "    oh = preprocessing.OneHotEncoder()\n",
      "    for colname, colseries in list(data.iteritems()):\n",
      "        protocol_name, feature_name = colname\n",
      "        \n",
      "        if colseries.dtype == object: # values are in string format\n",
      "            \n",
      "            # encode string values into integers, then reshape it into column\n",
      "            # array. reshaping is critical for binarization later.\n",
      "            le = preprocessing.LabelEncoder()\n",
      "            enc_values = le.fit_transform(colseries).reshape((len(colseries), 1))\n",
      "            \n",
      "            colnames = [  (\n",
      "                            header(protocol_name), \n",
      "                            \n",
      "                            '{feat}.{value}'.format(\n",
      "                                        feat=header(feature_name), \n",
      "                                        value=header(feature_value),\n",
      "                                          ),\n",
      "                          \n",
      "                          ) for feature_value in le.classes_ ]\n",
      "            values = oh.fit_transform(enc_values).todense().astype(bool)\n",
      "        \n",
      "        else:\n",
      "            colnames = [ (header(protocol_name), header(feature_name)) ]\n",
      "            values = colseries.values#.astype(float)# if colseries.dtype == bool else colseries.values\n",
      "        column_index = pd.MultiIndex.from_tuples(colnames, names=['Protocol', 'Feature name'])\n",
      "        \n",
      "        feature_data[colname] = pd.DataFrame(data=values, index=data.index, columns=column_index)\n",
      "    \n",
      "    return pd.concat(feature_data.values(), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = pd.Panel({context : encode_data(data_set(context)) for context in ('bound', 'unbound')})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p.save('peptidb.data.full.pkl')\n",
      "p.to_excel('peptidb.xlsx', )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = pd.DataFrame(p['unbound'].ix[:30,:20].dropna())\n",
      "r.astype(float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm_data.ix[(svm_data['NAccess']['All-atoms-rel'] >= 30.0)].ix[:30,:40]#.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save the data set as a `cPickle` file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#flat_svm_data = pd.DataFrame(svm_data.values, columns=pd.Index('.'.join(col) for col in svm_data.columns), index=svm_data.index)\n",
      "#flat_svm_data.ix[:10,35:50]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#flat_svm_data.to_csv('bound.data.full.csv', float_format='%.3f',)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}