{
 "metadata": {
  "name": "svm-preprocessing"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "SVM features: preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section we calculate quantitative residue descriptors used later in \n",
      "the SVM classification flow.\n",
      "\n",
      "We start by defining parameters of one PeptiDB entry, for which we calculate \n",
      "all the descriptors. \n",
      "\n",
      "The goal of each section is a function that accepts an AtomGroup object of \n",
      "the receptor (single chain), and optionally other parameters, returning a \n",
      "data frame or series object, with length equal to the number of residues in \n",
      "the receptor, where columns are one or more features of the residues. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# flag to mark cells that should run only in interactive mode\n",
      "interactive_session = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import prody\n",
      "prody.confProDy(verbosity='error')\n",
      "from sklearn import preprocessing\n",
      "\n",
      "import subprocess\n",
      "import tempfile\n",
      "import os, sys, shutil\n",
      "\n",
      "from collections import OrderedDict\n",
      "import itertools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import joblib\n",
      "memory = joblib.Memory('cache')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j = os.path.join\n",
      "PROJECT_PATH = '/home/assaff/projects/peptalk'\n",
      "\n",
      "DATA_PATH = j(PROJECT_PATH, 'data')\n",
      "PEPTIDB_DATA_PATH = j(DATA_PATH, 'peptiDB')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mem = joblib.Memory('cache')\n",
      "import naccess\n",
      "import fpocket\n",
      "\n",
      "class ReceptorData:\n",
      "    \n",
      "    def __init__(self, pdbid, bound=True):\n",
      "        self.pdbid = pdbid.upper()\n",
      "        self.context = 'bound' if bound else 'unbound'\n",
      "        \n",
      "        self.DATA_PATH = j(PEPTIDB_DATA_PATH, self.context)\n",
      "        self.PDB_DATA_PATH = j(self.DATA_PATH, self.context+'Set', 'mainChain' if bound else '')\n",
      "        self.FTMAP_DATA_PATH = j(self.DATA_PATH, 'FTMapAnalysis', 'ftmapData')\n",
      "        self.CONSURF_DATA_PATH = j(self.DATA_PATH, 'ConSurfAnalysis', 'data')\n",
      "        \n",
      "        self.receptor_filename = j(self.PDB_DATA_PATH, '%s.pdb' % self.pdbid)\n",
      "        self.receptor_atoms = prody.parsePDB(self.receptor_filename).protein\n",
      "        \n",
      "        self.receptor_chain = self.receptor_atoms.getHierView()['A']\n",
      "        self.resnum_index = pd.MultiIndex.from_tuples(\n",
      "                            zip(\n",
      "                                [pdbid]*self.receptor_chain.numResidues(),\n",
      "                                self.receptor_chain.ca.getResnums()\n",
      "                            ), \n",
      "                                names = [\n",
      "                                    'PDB identifier', \n",
      "                                    'Residue number',\n",
      "                                        ]\n",
      "                                )\n",
      "        self.df = pd.DataFrame(index=self.resnum_index)\n",
      "        print self.pdbid\n",
      "        \n",
      "    def conservation(self,):\n",
      "        consurf_pdb_filename = os.path.join(self.CONSURF_DATA_PATH, self.pdbid, 'pdbFILE_view_ConSurf.pdb')\n",
      "        p = prody.parsePDB(consurf_pdb_filename)\n",
      "        consurf_chain = p.getHierView()['A']\n",
      "        return pd.DataFrame(\n",
      "                            columns=['Conservation-score'],\n",
      "                            index=self.resnum_index,\n",
      "                            data=consurf_chain.ca.getBetas(),\n",
      "                            )\n",
      "    \n",
      "    def sasa(self,):\n",
      "        rsa = naccess.getResidueSasa(self.receptor_atoms)\n",
      "        return pd.DataFrame(\n",
      "                            rsa.values, \n",
      "                            index=self.resnum_index,\n",
      "                            columns=rsa.columns, \n",
      "                            )\n",
      "    \n",
      "    def ftmap(self,):\n",
      "        ######\n",
      "        # calculate consensus clusters (ccls) statistics, independent of specific residues:\n",
      "        ftmap_atoms = prody.parsePDB(j(self.FTMAP_DATA_PATH, '{}.map.clean.pdb'.format(self.pdbid)))\n",
      "        \n",
      "        ccls = pd.DataFrame(\n",
      "                            list(ftmap_atoms.getHierView().iterChains()), \n",
      "                            #index=range(h.numChains()),\n",
      "                            columns=['chain'],\n",
      "                            )\n",
      "        \n",
      "        ccls['cs_size'] = ccls.chain.map(lambda chain: chain.numResidues())\n",
      "        \n",
      "        ccls['cs_rank'] = ccls.cs_size.rank(ascending=False, method='first')\n",
      "        DUMMY_CCL_RANK = 15 #ccls.cs_rank.max()+1\n",
      "        \n",
      "        ######\n",
      "        def nearby_ccls(resnum, cutoff=4.5):\n",
      "            res = self.receptor_chain.getResidue(resnum)\n",
      "            res_contacts = prody.Contacts(res.noh.getCoords())\n",
      "            is_near_res = lambda ccl: res_contacts.select(cutoff, ccl) is not None\n",
      "                            #ag.select('same chain as within {} of res'.format(float(cutoff)), \n",
      "                            #                res=res) is not None\n",
      "            \n",
      "            return ccls[ccls.chain.map(is_near_res)].cs_rank.tolist()\n",
      "        \n",
      "        def nearby_ccl(resnum, cutoff=4.5):\n",
      "            ccls_near_ranks = nearby_ccls(resnum, cutoff)\n",
      "            return ccls_near_ranks[0] if ccls_near_ranks else DUMMY_CCL_RANK#np.nan\n",
      "        \n",
      "        def num_nearby_ccls(resnum):\n",
      "            return len(nearby_ccls(resnum))\n",
      "        \n",
      "        ind = pd.Index(self.receptor_chain.ca.getResnums())\n",
      "        \n",
      "        res_ccl_map = pd.DataFrame(\n",
      "                    columns=['resnum','cs_rank', 'num_nearby_cs'], \n",
      "                    data=zip(\n",
      "                        ind.tolist(), \n",
      "                        map(nearby_ccl, ind),\n",
      "                        map(num_nearby_ccls, ind),\n",
      "                        ),\n",
      "                    )\n",
      "        \n",
      "        ccls = ccls.append({'chain': None, 'cs_size': 1, 'cs_rank': DUMMY_CCL_RANK}, ignore_index=True)\n",
      "        \n",
      "        ccls['cs_normalized_rank'] = ccls.cs_rank / ccls.cs_size\n",
      "        \n",
      "        ccls['cs_svm_size'] = np.minimum(\n",
      "                                    np.ceil(ccls.cs_size / float(5)),\n",
      "                                    4\n",
      "                                    )\n",
      "        ccls['cs_svm_rank'] = np.minimum(ccls.cs_rank, 5)\n",
      "        \n",
      "        ccls['cs_svm_norm_rank'] = ccls['cs_svm_rank'] / ccls['cs_svm_size'].astype(float)\n",
      "        \n",
      "        \n",
      "        res_ccl_stats = res_ccl_map.merge(\n",
      "                        ccls.drop(['chain'], axis=1), \n",
      "                        how='inner', \n",
      "                        on='cs_rank',\n",
      "                            ).set_index('resnum')\n",
      "        return res_ccl_stats.reindex(index=self.resnum_index, level=1)\n",
      "    \n",
      "    def pockets(self,):\n",
      "        pocket_data = fpocket.pocket_data(self.receptor_filename)\n",
      "        DUMMY_POCKET_RANK = 15#pocket_data['Pocket rank'].max()+1\n",
      "        \n",
      "        def nearby_pocket(resnum, cutoff=4.5):\n",
      "            \n",
      "            res = self.receptor_chain.getResidue(resnum)\n",
      "        \n",
      "            res_contacts = prody.Contacts(res.noh.getCoords())\n",
      "            is_near_res = lambda pocket_atoms: res_contacts.select(cutoff, pocket_atoms) is not None\n",
      "        \n",
      "            pockets_near_rank = pocket_data.ix[\n",
      "                            pocket_data['Pocket atoms'].map(is_near_res), \n",
      "                            'Pocket rank'\n",
      "                                ].tolist()\n",
      "            return pockets_near_rank[0] if pockets_near_rank else DUMMY_POCKET_RANK# np.nan\n",
      "            \n",
      "        res_pocket_map = pd.DataFrame(\n",
      "                              columns = ['resnum', 'Pocket rank'],\n",
      "                              index=self.resnum_index,\n",
      "                              data=[(resnum, nearby_pocket(resnum)) for resnum \n",
      "                                    in self.resnum_index.get_level_values(1)],\n",
      "                              )\n",
      "        pocket_data = pocket_data.append({colname: DUMMY_POCKET_RANK if colname=='Pocket rank' else 0 \n",
      "                            for colname in pocket_data.columns}, \n",
      "                                ignore_index=True,)\n",
      "        \n",
      "        res_pocket_stats = res_pocket_map.merge(\n",
      "                            pocket_data.drop(['Pocket atoms'], axis=1), \n",
      "                            how='inner', \n",
      "                            on='Pocket rank', \n",
      "                                ).set_index('resnum')\n",
      "        \n",
      "        return res_pocket_stats.reindex(res_pocket_map.index, level=1)\n",
      "    \n",
      "    def aa_props(self,):\n",
      "        aa_props = pd.read_csv('aa_props.csv', true_values='X', false_values='-',)\n",
      "        aa_props['resname'] = [s.upper() for s in aa_props['Abbrev.']]\n",
      "        \n",
      "        aa_props['pKa'] = [float(n) for n in aa_props['pKa'].replace('-', '0.0')]\n",
      "        aa_props = aa_props.replace('-', 'None')\n",
      "        aa_props = aa_props.ix[:, 'Hydrophobic':]\n",
      "        \n",
      "        res_aa_map = pd.DataFrame(\n",
      "                              columns=['resnum', 'resname'],\n",
      "                              index=self.resnum_index,\n",
      "                              data=[(resnum, self.receptor_chain.getResidue(resnum).getResname())\n",
      "                                    for resnum in self.resnum_index.get_level_values(1)],\n",
      "                            )\n",
      "        res_aa_stats = res_aa_map.merge(aa_props, how='inner', on='resname',).set_index('resnum')\n",
      "        return res_aa_stats.reindex(res_aa_map.index, level=1)\n",
      "            \n",
      "    #@property\n",
      "    def data(self,):\n",
      "        if not hasattr(self, '_data'):\n",
      "            feature_generators = OrderedDict(\n",
      "                                         NAccess=self.sasa(),\n",
      "                                         ConSurf=self.conservation(),\n",
      "                                         FTMap=self.ftmap(),\n",
      "                                         FPocket=self.pockets(),\n",
      "                                         Physico=self.aa_props(),\n",
      "                                         )\n",
      "            \n",
      "            tuples = list(itertools.chain(*[\n",
      "                         [(prot_name, col_name) for col_name in prot_df.columns.tolist()]\n",
      "                         for prot_name, prot_df in feature_generators.items()\n",
      "                     ]))\n",
      "            idex = pd.MultiIndex.from_tuples(tuples)\n",
      "            \n",
      "            self._data = pd.concat(feature_generators.values(), axis=1, keys=feature_generators.keys())\n",
      "        return self._data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@memory.cache\n",
      "def recdata(pdbid):\n",
      "    return ReceptorData(pdbid).data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = recdata('1AWR')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Aggregating over all entries in PeptiDB:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdbs_list = pd.read_csv('archive_2013-02-13/pdb_list.txt', header=None)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bound_data = pd.concat([recdata(pdbid) for pdbid in pdbs_list],)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_data = OrderedDict()\n",
      "oh = preprocessing.OneHotEncoder()\n",
      "for colname, colseries in list(bound_data.iteritems()):\n",
      "    protocol_name, feature_name = colname\n",
      "    \n",
      "    if colseries.dtype == object: # values are in string format\n",
      "        \n",
      "        # encode string values into integers, then reshape it into column\n",
      "        # array. reshaping is critical for binarization later.\n",
      "        le = preprocessing.LabelEncoder()\n",
      "        enc_values = le.fit_transform(colseries).reshape((len(colseries), 1))\n",
      "        \n",
      "        colnames = [  (\n",
      "                        protocol_name, \n",
      "                        \n",
      "                        '{feat}.{value}'.format(\n",
      "                                    feat='-'.join(feature_name.split()), \n",
      "                                    value='-'.join(str(feature_value).split())\n",
      "                                      ),\n",
      "                      \n",
      "                      ) for feature_value in le.classes_ ]\n",
      "        values = oh.fit_transform(enc_values).todense()\n",
      "    \n",
      "    else:\n",
      "        colnames = [ colname, ]\n",
      "        values = colseries.astype(float).values\n",
      "    column_index = pd.MultiIndex.from_tuples(colnames)\n",
      "    \n",
      "    feature_data[colname] = pd.DataFrame(data=values, index=bound_data.index, columns=column_index)\n",
      "\n",
      "svm_data = pd.concat(feature_data.values(), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see how big our surface-residue data set is, and if it's comparable to the old one:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm_data.ix[(svm_data['NAccess']['All-atoms-rel'] >= 30.0)].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save the data set as a `cPickle` file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm_data.save('bound.data.full.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}